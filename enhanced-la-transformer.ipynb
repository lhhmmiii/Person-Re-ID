{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8375660,"sourceType":"datasetVersion","datasetId":4980010},{"sourceId":8391348,"sourceType":"datasetVersion","datasetId":4991449}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Import library","metadata":{}},{"cell_type":"code","source":"# Regarding pytorch\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport torch.optim as optim\n# Other\nimport timm\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom tqdm.notebook import tqdm\nimport os\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-05-13T03:28:50.118519Z","iopub.execute_input":"2024-05-13T03:28:50.119252Z","iopub.status.idle":"2024-05-13T03:28:57.503590Z","shell.execute_reply.started":"2024-05-13T03:28:50.119218Z","shell.execute_reply":"2024-05-13T03:28:57.502786Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# 2. Dataset","metadata":{}},{"cell_type":"code","source":"train_path = '/kaggle/input/market-dataset-2/Market-Pytorch/Market/train/'\nval_path = '/kaggle/input/market-dataset-2/Market-Pytorch/Market/val/'","metadata":{"execution":{"iopub.status.busy":"2024-05-13T03:28:57.505076Z","iopub.execute_input":"2024-05-13T03:28:57.505365Z","iopub.status.idle":"2024-05-13T03:28:57.510033Z","shell.execute_reply.started":"2024-05-13T03:28:57.505341Z","shell.execute_reply":"2024-05-13T03:28:57.508864Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def extractImageandLabel(path):\n    list_subfolder = os.listdir(path)\n    list_images = []\n    list_classes = []\n    list_labels = []\n    for i, subfolder in enumerate(list_subfolder):\n        _class = int(subfolder) # Class của đối tượng\n        sub_path = path + subfolder + '/' # Đường dẫn đến folder chứa các ảnh thuộc cùng 1 class\n        list_image_names = os.listdir(sub_path) # Tên các ảnh của folder ở trên\n        list_image_paths = [sub_path + name for name in list_image_names] # Đường dẫn tới các ảnh đó\n        for image_path in list_image_paths:\n            image = Image.open(image_path)\n            list_images.append(image)\n            list_classes.append(_class)\n            list_labels.append(i)\n    return list_images, list_classes, list_labels","metadata":{"execution":{"iopub.status.busy":"2024-05-13T03:28:57.511311Z","iopub.execute_input":"2024-05-13T03:28:57.511666Z","iopub.status.idle":"2024-05-13T03:28:57.522285Z","shell.execute_reply.started":"2024-05-13T03:28:57.511601Z","shell.execute_reply":"2024-05-13T03:28:57.521410Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_list_images, train_list_classes, train_list_labels = extractImageandLabel(train_path)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T03:28:57.524387Z","iopub.execute_input":"2024-05-13T03:28:57.524915Z","iopub.status.idle":"2024-05-13T03:30:00.668490Z","shell.execute_reply.started":"2024-05-13T03:28:57.524891Z","shell.execute_reply":"2024-05-13T03:30:00.667662Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"val_list_images, val_list_classes, val_list_labels = extractImageandLabel(val_path)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T03:30:00.669764Z","iopub.execute_input":"2024-05-13T03:30:00.670073Z","iopub.status.idle":"2024-05-13T03:30:07.168376Z","shell.execute_reply.started":"2024-05-13T03:30:00.670049Z","shell.execute_reply":"2024-05-13T03:30:07.167185Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print('Số lượng ảnh ở tập train: ', len(train_list_images))\nprint('Số lượng lớp ở tập train: ', len(set(train_list_classes)))\nprint('Số lượng ảnh ở tập val: ', len(val_list_images))\nprint('Số lượng lớp ở tập val: ', len(set(val_list_classes)))","metadata":{"execution":{"iopub.status.busy":"2024-05-13T03:30:07.169742Z","iopub.execute_input":"2024-05-13T03:30:07.170033Z","iopub.status.idle":"2024-05-13T03:30:07.176990Z","shell.execute_reply.started":"2024-05-13T03:30:07.170008Z","shell.execute_reply":"2024-05-13T03:30:07.175982Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Số lượng ảnh ở tập train:  12185\nSố lượng lớp ở tập train:  751\nSố lượng ảnh ở tập val:  751\nSố lượng lớp ở tập val:  751\n","output_type":"stream"}]},{"cell_type":"code","source":"transform_train_list = [\n    transforms.Resize((224,224), interpolation= 3),\n    transforms.ToTensor(),\n    transforms.RandomHorizontalFlip(),\n#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n]\ntransform_val_list = [\n    transforms.Resize((224, 224), interpolation= 3),\n    transforms.ToTensor(),\n#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n]\ndata_transforms = [\n    transforms.Compose(transform_train_list), # train\n    transforms.Compose(transform_val_list) # val\n]","metadata":{"execution":{"iopub.status.busy":"2024-05-13T03:30:07.178198Z","iopub.execute_input":"2024-05-13T03:30:07.178457Z","iopub.status.idle":"2024-05-13T03:30:07.189000Z","shell.execute_reply.started":"2024-05-13T03:30:07.178434Z","shell.execute_reply":"2024-05-13T03:30:07.188135Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class TrainValDataset(Dataset):\n    def __init__(self, list_images, list_labels, data_transforms, is_train = True):\n        self.list_images = list_images\n        self.list_labels = list_labels\n        self.data_transforms = data_transforms\n        self.is_train = is_train\n    def __len__(self):\n        return len(self.list_images)\n    def __getitem__(self, idx):\n        label = self.list_labels[idx] # label\n        # Image\n        image = self.list_images[idx]\n        transform = self.data_transforms[0]   \n        if not self.is_train:\n            transform = self.data_transforms[1]\n        image = transform(image)\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-05-13T03:30:07.190198Z","iopub.execute_input":"2024-05-13T03:30:07.191043Z","iopub.status.idle":"2024-05-13T03:30:07.202325Z","shell.execute_reply.started":"2024-05-13T03:30:07.191011Z","shell.execute_reply":"2024-05-13T03:30:07.201518Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_dataset = TrainValDataset(train_list_images, train_list_labels, data_transforms)\nval_dataset = TrainValDataset(val_list_images, val_list_labels, data_transforms, is_train = False)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T03:30:07.203519Z","iopub.execute_input":"2024-05-13T03:30:07.204141Z","iopub.status.idle":"2024-05-13T03:30:07.211601Z","shell.execute_reply.started":"2024-05-13T03:30:07.204107Z","shell.execute_reply":"2024-05-13T03:30:07.210751Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, shuffle = True, batch_size = 32)\nval_loader = DataLoader(val_dataset, shuffle = True, batch_size = 32)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T03:30:07.215386Z","iopub.execute_input":"2024-05-13T03:30:07.215712Z","iopub.status.idle":"2024-05-13T03:30:07.221963Z","shell.execute_reply.started":"2024-05-13T03:30:07.215687Z","shell.execute_reply":"2024-05-13T03:30:07.221170Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"a, b = next(iter(train_loader)) # Dùng để kiểm tra code TrainValDataset chạy đúng không","metadata":{"execution":{"iopub.status.busy":"2024-05-13T03:30:07.222932Z","iopub.execute_input":"2024-05-13T03:30:07.223228Z","iopub.status.idle":"2024-05-13T03:30:07.421749Z","shell.execute_reply.started":"2024-05-13T03:30:07.223203Z","shell.execute_reply":"2024-05-13T03:30:07.420898Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# 3. Model","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-05-13T03:30:07.422985Z","iopub.execute_input":"2024-05-13T03:30:07.423630Z","iopub.status.idle":"2024-05-13T03:30:07.451757Z","shell.execute_reply.started":"2024-05-13T03:30:07.423585Z","shell.execute_reply":"2024-05-13T03:30:07.450783Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}]},{"cell_type":"code","source":"# Load pre-trained ViT\nvit_base = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=751)\nvit_base= vit_base.to(device)\nvit_base.eval()","metadata":{"execution":{"iopub.status.busy":"2024-05-13T03:30:07.452963Z","iopub.execute_input":"2024-05-13T03:30:07.453257Z","iopub.status.idle":"2024-05-13T03:30:18.990416Z","shell.execute_reply.started":"2024-05-13T03:30:07.453233Z","shell.execute_reply":"2024-05-13T03:30:18.989425Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2de858a0566846eaba326a1c5bf666c2"}},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"VisionTransformer(\n  (patch_embed): PatchEmbed(\n    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n    (norm): Identity()\n  )\n  (pos_drop): Dropout(p=0.0, inplace=False)\n  (patch_drop): Identity()\n  (norm_pre): Identity()\n  (blocks): Sequential(\n    (0): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (1): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (2): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (3): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (4): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (5): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (6): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (7): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (8): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (9): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (10): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n    (11): Block(\n      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (attn): Attention(\n        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n        (q_norm): Identity()\n        (k_norm): Identity()\n        (attn_drop): Dropout(p=0.0, inplace=False)\n        (proj): Linear(in_features=768, out_features=768, bias=True)\n        (proj_drop): Dropout(p=0.0, inplace=False)\n      )\n      (ls1): Identity()\n      (drop_path1): Identity()\n      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n      (mlp): Mlp(\n        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n        (act): GELU(approximate='none')\n        (drop1): Dropout(p=0.0, inplace=False)\n        (norm): Identity()\n        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n        (drop2): Dropout(p=0.0, inplace=False)\n      )\n      (ls2): Identity()\n      (drop_path2): Identity()\n    )\n  )\n  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n  (fc_norm): Identity()\n  (head_drop): Dropout(p=0.0, inplace=False)\n  (head): Linear(in_features=768, out_features=751, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"class FCLayer(nn.Module):\n    def __init__(self, input_dim=768, num_bottleneck=512, num_classes=751):\n        super().__init__()\n        self.input_dim = input_dim\n        self.num_bottleneck = num_bottleneck\n        self.num_classes = num_classes\n        self.linear1 = nn.Linear(self.input_dim, self.num_bottleneck)\n        self.linear2 = nn.Linear(self.num_bottleneck, self.num_classes)\n        self.ReLU = nn.ReLU()\n        self.batch_norm = nn.BatchNorm1d(self.num_bottleneck)\n        \n        \n    def forward(self, x):\n        x = self.linear1(x)\n        x = self.ReLU(x)\n        x = self.batch_norm(x)\n        x = self.linear2(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-05-13T03:30:18.991579Z","iopub.execute_input":"2024-05-13T03:30:18.991884Z","iopub.status.idle":"2024-05-13T03:30:18.999375Z","shell.execute_reply.started":"2024-05-13T03:30:18.991859Z","shell.execute_reply":"2024-05-13T03:30:18.998399Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class LATransformer(nn.Module):\n    def __init__(self, backbone_model, _lambda):\n        super().__init__()\n        self.backbone_model = backbone_model\n        self._lambda = _lambda\n        self.avgpool = nn.AdaptiveAvgPool2d((1,768))\n        self.fc_layers = nn.ModuleList([FCLayer() for _ in range(3)])\n        \n    def forward(self, x):\n        x = self.backbone_model.patch_embed(x)\n        cls_token = self.backbone_model.cls_token.expand(x.shape[0], -1, -1)\n        x = torch.cat((cls_token, x), dim=1)\n        x = self.backbone_model.pos_drop(x + self.backbone_model.pos_embed)\n\n        # Feed forward through transformer blocks\n        for i in range(12):\n            x = self.backbone_model.blocks[i](x)\n        x = self.backbone_model.norm(x)\n\n        # extract the cls token\n        G = x[:,0,:].unsqueeze(1) # cls\n        Q = x[:,1:,:] # local feature # (batch_size, 128, 768)\n        Q1 = Q[:,0:36,:]\n        Q2 = Q[:,28:160,:]\n        Q3 = Q[:,128:,:]\n        f = [self.avgpool(Q1), self.avgpool(Q2), self.avgpool(Q3)]\n        for i in range(3):\n            out = torch.mul(f[i], self._lambda).squeeze()\n            f[i] = torch.div(torch.add(G.squeeze(),out), 1+self._lambda)\n        y = []\n        for i in range(3):\n            y_i = self.fc_layers[i](f[i])\n            y.append(y_i)\n            \n        return f, y","metadata":{"execution":{"iopub.status.busy":"2024-05-13T03:30:19.000779Z","iopub.execute_input":"2024-05-13T03:30:19.001091Z","iopub.status.idle":"2024-05-13T03:30:19.014576Z","shell.execute_reply.started":"2024-05-13T03:30:19.001056Z","shell.execute_reply":"2024-05-13T03:30:19.013568Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"la_transformer_model = LATransformer(vit_base, 8).to(device)\n# la_transformer_model.load_state_dict(torch.load('/kaggle/input/best-model/best_model.pth'))\nCE_loss = nn.CrossEntropyLoss()\noptimizer = optim.Adam(la_transformer_model.parameters(), lr=0.0001)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T03:30:19.015741Z","iopub.execute_input":"2024-05-13T03:30:19.016027Z","iopub.status.idle":"2024-05-13T03:30:19.054282Z","shell.execute_reply.started":"2024-05-13T03:30:19.016003Z","shell.execute_reply":"2024-05-13T03:30:19.053577Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def freeze_all_blocks(model):\n    num_blocks = 12\n    for block in model.backbone_model.blocks[:num_blocks]:\n        for param in block.parameters():\n            param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2024-05-13T03:30:19.055286Z","iopub.execute_input":"2024-05-13T03:30:19.055562Z","iopub.status.idle":"2024-05-13T03:30:19.060344Z","shell.execute_reply.started":"2024-05-13T03:30:19.055537Z","shell.execute_reply":"2024-05-13T03:30:19.059454Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def unfreeze(model, num_blocks, remaining_count):\n    block = model.backbone_model.blocks[remaining_count - 1]\n    for param in block.parameters():\n        param.requires_grad = True","metadata":{"execution":{"iopub.status.busy":"2024-05-13T03:30:19.061395Z","iopub.execute_input":"2024-05-13T03:30:19.061722Z","iopub.status.idle":"2024-05-13T03:30:19.069654Z","shell.execute_reply.started":"2024-05-13T03:30:19.061697Z","shell.execute_reply":"2024-05-13T03:30:19.068765Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# 4. Train","metadata":{}},{"cell_type":"code","source":"# Train mà không dung block wise\ndef train(model, train_loader, num_epochs):\n    softmax = nn.Softmax(dim = 1)\n    for epoch in range(num_epochs):\n        model.train()\n        correct = 0\n        total_loss = 0\n        for image, label in tqdm(train_loader):\n            optimizer.zero_grad()\n            image, label = image.to(device), label.to(device)\n            _, outputs = model(image)\n            score = 0\n            loss = 0.0\n            for output in outputs:\n                score += softmax(output)\n                loss += CE_loss(output, label)\n            total_loss += loss.item()\n            #\n            loss.backward()\n            optimizer.step()\n            #\n            pred = torch.argmax(score, dim = 1)\n            correct += (pred == label).sum()\n            #\n        avg_loss = total_loss/len(train_list_images)\n        file_path = f'/kaggle/working/model_epoch_{epoch}.pth'\n        torch.save(model.state_dict(), file_path)\n        print(f'Epoch {epoch}: Loss: {avg_loss} Train_accuracy: {correct/len(train_list_images)}')","metadata":{"execution":{"iopub.status.busy":"2024-05-12T12:37:27.822613Z","iopub.execute_input":"2024-05-12T12:37:27.823298Z","iopub.status.idle":"2024-05-12T12:37:27.832402Z","shell.execute_reply.started":"2024-05-12T12:37:27.823266Z","shell.execute_reply":"2024-05-12T12:37:27.831283Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"train(la_transformer_model, train_loader, 1)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T12:37:28.222697Z","iopub.execute_input":"2024-05-12T12:37:28.223510Z","iopub.status.idle":"2024-05-12T12:41:14.337292Z","shell.execute_reply.started":"2024-05-12T12:37:28.223475Z","shell.execute_reply":"2024-05-12T12:41:14.336249Z"},"trusted":true},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/381 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23ffa0e9c39046a4bc768f6633a754c8"}},"metadata":{}},{"name":"stdout","text":"Epoch 13: Loss: 0.003277631509005045 Train_accuracy: 0.9967993497848511\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train sử dụng block wise\ndef train_with_blockwise(model, train_loader, num_epochs, t = 2, lr_decay = 0.85):\n    softmax = nn.Softmax(dim = 1)\n    freeze_all_blocks(model)\n    count = 0\n    for epoch in range(num_epochs):\n        model.train()\n        if epoch > 0 and epoch % t ==0:\n            count += 1\n            remaining_cout = 12 - count\n            unfreeze(model, 12, remaining_cout)\n            optimizer.param_groups[0]['lr'] *= lr_decay\n        correct = 0\n        total_loss = 0\n        for image, label in tqdm(train_loader):\n            optimizer.zero_grad()\n            image, label = image.to(device), label.to(device)\n            _, outputs = model(image)\n            score = 0\n            loss = 0.0\n            for output in outputs:\n                score += softmax(output)\n                loss += CE_loss(output, label)\n            total_loss += loss.item()\n            #\n            loss.backward()\n            optimizer.step()\n            #\n            pred = torch.argmax(score, dim = 1)\n            correct += (pred == label).sum()\n            #\n        avg_loss = total_loss/len(train_list_images)\n        file_path = f'/kaggle/working/model_epoch_{epoch}.pth'\n        torch.save(model.state_dict(), file_path)\n        print(f'Epoch {epoch}: Loss: {avg_loss} Train_accuracy: {correct/len(train_list_images)}')","metadata":{"execution":{"iopub.status.busy":"2024-05-13T03:30:19.070796Z","iopub.execute_input":"2024-05-13T03:30:19.071057Z","iopub.status.idle":"2024-05-13T03:30:19.310955Z","shell.execute_reply.started":"2024-05-13T03:30:19.071010Z","shell.execute_reply":"2024-05-13T03:30:19.309797Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_with_blockwise(la_transformer_model,train_loader, 26)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T03:30:19.312350Z","iopub.execute_input":"2024-05-13T03:30:19.312683Z","iopub.status.idle":"2024-05-13T04:31:57.781745Z","shell.execute_reply.started":"2024-05-13T03:30:19.312653Z","shell.execute_reply":"2024-05-13T04:31:57.780397Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/381 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3d63af127d6472097e90b0939e98c34"}},"metadata":{}},{"name":"stdout","text":"Epoch 0: Loss: 0.5747545452845796 Train_accuracy: 0.09995896369218826\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/381 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e92dd2991b74c24b239c1d354d292dc"}},"metadata":{}},{"name":"stdout","text":"Epoch 1: Loss: 0.4162617938949967 Train_accuracy: 0.3189987540245056\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/381 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"287fb87782ca47e4add2088be3eae135"}},"metadata":{}},{"name":"stdout","text":"Epoch 2: Loss: 0.27472100091557744 Train_accuracy: 0.5643003582954407\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/381 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3ccf64d1eed4df688fed355becf5129"}},"metadata":{}},{"name":"stdout","text":"Epoch 3: Loss: 0.16341195010630186 Train_accuracy: 0.7763643860816956\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/381 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14226e0fac2e43e6ae97cc25971e2f59"}},"metadata":{}},{"name":"stdout","text":"Epoch 4: Loss: 0.09132582433017297 Train_accuracy: 0.897661030292511\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/381 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f72d1531a2164ea29cd255fb616881ff"}},"metadata":{}},{"name":"stdout","text":"Epoch 5: Loss: 0.04508650524478297 Train_accuracy: 0.9610996842384338\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/381 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"627d49e0d1314b37bafd95037531bf5c"}},"metadata":{}},{"name":"stdout","text":"Epoch 6: Loss: 0.022324143201540764 Train_accuracy: 0.9875256419181824\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/381 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa922b36b72f4e8a92641600d145bc75"}},"metadata":{}},{"name":"stdout","text":"Epoch 7: Loss: 0.010206138169271416 Train_accuracy: 0.9959786534309387\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/381 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"018e217e0ee546078c3760dfd97492b7"}},"metadata":{}},{"name":"stdout","text":"Epoch 8: Loss: 0.006202331093011159 Train_accuracy: 0.9978662133216858\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/381 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89e589bd915e4b8c95d0fd8f25e7ef90"}},"metadata":{}},{"name":"stdout","text":"Epoch 9: Loss: 0.0035050896741984855 Train_accuracy: 0.9993434548377991\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/381 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63a3ff92c8214e9bab515127cbc7b520"}},"metadata":{}},{"name":"stdout","text":"Epoch 10: Loss: 0.0027046276663824044 Train_accuracy: 0.9995076060295105\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/381 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b63761907ba14e56b385915e91798c19"}},"metadata":{}},{"name":"stdout","text":"Epoch 11: Loss: 0.00265907961500684 Train_accuracy: 0.9989331364631653\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/381 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6654a0eed8594487bf3c4d64f642a543"}},"metadata":{}},{"name":"stdout","text":"Epoch 12: Loss: 0.0023332517248626904 Train_accuracy: 0.9988510608673096\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/381 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"598445af5aa144cba2d4642ddb3193ac"}},"metadata":{}},{"name":"stdout","text":"Epoch 13: Loss: 0.001062766525238618 Train_accuracy: 0.9998358488082886\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/381 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1cb0baaa6044b3d8ca0cfd0bf0934f3"}},"metadata":{}},{"name":"stdout","text":"Epoch 14: Loss: 0.0007165659988695694 Train_accuracy: 1.0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/381 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39a1af713a55497fab4a0ec68338a308"}},"metadata":{}},{"name":"stdout","text":"Epoch 15: Loss: 0.0005622121790530229 Train_accuracy: 1.0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/381 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6ff25f5d7fb44559ae8e01edab92cea"}},"metadata":{}},{"name":"stdout","text":"Epoch 16: Loss: 0.0004736749965515619 Train_accuracy: 1.0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/381 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9609ec20bad4cd2bf807604372f73a8"}},"metadata":{}},{"name":"stdout","text":"Epoch 17: Loss: 0.00039759337963978924 Train_accuracy: 1.0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/381 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"351f6fb2acdb4ddabf3bf2d7432bb742"}},"metadata":{}},{"name":"stdout","text":"Epoch 18: Loss: 0.00034603791075973027 Train_accuracy: 1.0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/381 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1db1ac4549e940ad8369667e73cf1150"}},"metadata":{}},{"name":"stdout","text":"Epoch 19: Loss: 0.0026108652753789843 Train_accuracy: 0.9975379705429077\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/381 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aadb2dc1667c47ac80efbe4d448baf7d"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_with_blockwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mla_transformer_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m26\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[19], line 24\u001b[0m, in \u001b[0;36mtrain_with_blockwise\u001b[0;34m(model, train_loader, num_epochs, t, lr_decay)\u001b[0m\n\u001b[1;32m     22\u001b[0m     score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m softmax(output)\n\u001b[1;32m     23\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m CE_loss(output, label)\n\u001b[0;32m---> 24\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     26\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"os.chdir(r'/kaggle/working')\nfrom IPython.display import FileLink\nFileLink(r'model_epoch_19.pth')","metadata":{"execution":{"iopub.status.busy":"2024-05-13T04:32:17.808493Z","iopub.execute_input":"2024-05-13T04:32:17.809252Z","iopub.status.idle":"2024-05-13T04:32:17.815650Z","shell.execute_reply.started":"2024-05-13T04:32:17.809221Z","shell.execute_reply":"2024-05-13T04:32:17.814596Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/model_epoch_19.pth","text/html":"<a href='model_epoch_19.pth' target='_blank'>model_epoch_19.pth</a><br>"},"metadata":{}}]},{"cell_type":"markdown","source":"# 5. Validate","metadata":{}},{"cell_type":"code","source":"def validate(model, val_loader):\n    correct = 0\n    total = 751\n    total_loss = 0\n    softmax = nn.Softmax(dim = 1)\n    for image, label in tqdm(val_loader):\n        image, label = image.to(device), label.to(device)\n        score = 0\n        loss = 0\n        with torch.no_grad():\n            _, outputs = model(image)\n            for output in outputs:\n                score += softmax(output)\n                loss += CE_loss(output, label)\n            total_loss += loss.item()\n            pred = torch.argmax(score, dim = 1)\n            correct += (pred == label).sum()\n    avg_loss = total_loss/total\n    print(f'Loss: {avg_loss} Val_accuracy: {correct/total}')    ","metadata":{"execution":{"iopub.status.busy":"2024-05-13T04:32:29.964800Z","iopub.execute_input":"2024-05-13T04:32:29.965185Z","iopub.status.idle":"2024-05-13T04:32:29.972790Z","shell.execute_reply.started":"2024-05-13T04:32:29.965159Z","shell.execute_reply":"2024-05-13T04:32:29.971744Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"validate(la_transformer_model, val_loader)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T04:32:30.636067Z","iopub.execute_input":"2024-05-13T04:32:30.636459Z","iopub.status.idle":"2024-05-13T04:32:38.435847Z","shell.execute_reply.started":"2024-05-13T04:32:30.636429Z","shell.execute_reply":"2024-05-13T04:32:38.434764Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/24 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e55ee23d86604c6ead83aeb67c1cc14b"}},"metadata":{}},{"name":"stdout","text":"Loss: 0.05136664324848058 Val_accuracy: 0.9001331329345703\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 6. Test","metadata":{}},{"cell_type":"code","source":"query_path = '/kaggle/input/market-dataset-2/Market-Pytorch/Market/query/'\ngallery_path = '/kaggle/input/market-dataset-2/Market-Pytorch/Market/gallery/'","metadata":{"execution":{"iopub.status.busy":"2024-05-13T04:32:43.248393Z","iopub.execute_input":"2024-05-13T04:32:43.248787Z","iopub.status.idle":"2024-05-13T04:32:43.253438Z","shell.execute_reply.started":"2024-05-13T04:32:43.248756Z","shell.execute_reply":"2024-05-13T04:32:43.252400Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"list_subfolder = os.listdir('/kaggle/input/market-dataset-2/Market-Pytorch/Market/gallery/')\ndictionary = {}\nfor i, subfolder in enumerate(list_subfolder):\n    _class = int(subfolder)\n    dictionary[_class] = i","metadata":{"execution":{"iopub.status.busy":"2024-05-13T04:32:43.494123Z","iopub.execute_input":"2024-05-13T04:32:43.495030Z","iopub.status.idle":"2024-05-13T04:32:43.957185Z","shell.execute_reply.started":"2024-05-13T04:32:43.494995Z","shell.execute_reply":"2024-05-13T04:32:43.956125Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def extractImageandLabelTest(path, dictionary):\n    list_subfolder = os.listdir(path)\n    list_images = []\n    list_labels = []\n    for i, subfolder in enumerate(list_subfolder):\n        _class = int(subfolder) # Class của đối tượng\n        sub_path = path + subfolder + '/' # Đường dẫn đến folder chứa các ảnh thuộc cùng 1 class\n        list_image_names = os.listdir(sub_path) # Tên các ảnh của folder ở trên\n        list_image_paths = [sub_path + name for name in list_image_names] # Đường dẫn tới các ảnh đó\n        for image_path in list_image_paths:\n            image = Image.open(image_path)\n            list_images.append(image)   \n            list_labels.append(dictionary[_class])\n    return list_images, list_labels","metadata":{"execution":{"iopub.status.busy":"2024-05-13T04:32:43.958937Z","iopub.execute_input":"2024-05-13T04:32:43.959247Z","iopub.status.idle":"2024-05-13T04:32:43.966624Z","shell.execute_reply.started":"2024-05-13T04:32:43.959222Z","shell.execute_reply":"2024-05-13T04:32:43.965633Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"gallery_list_images, gallery_list_labels  = extractImageandLabelTest(gallery_path, dictionary)\nquery_list_images, query_list_labels  = extractImageandLabelTest(query_path, dictionary)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T04:32:43.967979Z","iopub.execute_input":"2024-05-13T04:32:43.968418Z","iopub.status.idle":"2024-05-13T04:36:27.815159Z","shell.execute_reply.started":"2024-05-13T04:32:43.968385Z","shell.execute_reply":"2024-05-13T04:36:27.813823Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"print('Số lượng ảnh trong gallery: ', len(gallery_list_images))\nprint('Số lượng class trong gallery: ', len(set(gallery_list_labels)))\nprint('Số lượng ảnh trong query: ', len(query_list_images))\nprint('Số lượng class trong query: ', len(set(query_list_labels)))","metadata":{"execution":{"iopub.status.busy":"2024-05-13T04:36:27.818628Z","iopub.execute_input":"2024-05-13T04:36:27.819248Z","iopub.status.idle":"2024-05-13T04:36:27.828266Z","shell.execute_reply.started":"2024-05-13T04:36:27.819211Z","shell.execute_reply":"2024-05-13T04:36:27.827169Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Số lượng ảnh trong gallery:  19732\nSố lượng class trong gallery:  752\nSố lượng ảnh trong query:  3368\nSố lượng class trong query:  750\n","output_type":"stream"}]},{"cell_type":"code","source":"gallery_dataset = TrainValDataset(gallery_list_images, gallery_list_labels, data_transforms, is_train = False)\nquery_dataset = TrainValDataset(query_list_images, query_list_labels, data_transforms)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T04:36:27.829872Z","iopub.execute_input":"2024-05-13T04:36:27.830254Z","iopub.status.idle":"2024-05-13T04:36:27.836441Z","shell.execute_reply.started":"2024-05-13T04:36:27.830214Z","shell.execute_reply":"2024-05-13T04:36:27.835342Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"query_loader = DataLoader(query_dataset, batch_size = 16, shuffle=False)\ngallery_loader = DataLoader(gallery_dataset, batch_size = 16, shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T04:36:27.837812Z","iopub.execute_input":"2024-05-13T04:36:27.838170Z","iopub.status.idle":"2024-05-13T04:36:27.846813Z","shell.execute_reply.started":"2024-05-13T04:36:27.838135Z","shell.execute_reply":"2024-05-13T04:36:27.845832Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def extract_feature(model, dataloader):\n    features = torch.FloatTensor().to(device)\n    for image, label in tqdm(dataloader):\n        image, label = image.to(device), label.to(device)\n        with torch.no_grad():\n            f, _ = model(image)\n            temp = torch.cat((f[0], f[1]), dim = 1)\n            f123 = torch.cat((temp, f[2]), dim = 1)\n            features = torch.cat((features, f123), dim = 0)\n    return features","metadata":{"execution":{"iopub.status.busy":"2024-05-13T04:36:27.848072Z","iopub.execute_input":"2024-05-13T04:36:27.848477Z","iopub.status.idle":"2024-05-13T04:36:27.857892Z","shell.execute_reply.started":"2024-05-13T04:36:27.848440Z","shell.execute_reply":"2024-05-13T04:36:27.856597Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"query_feature= extract_feature(la_transformer_model, query_loader)\ngallery_feature = extract_feature(la_transformer_model, gallery_loader)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T04:36:27.862169Z","iopub.execute_input":"2024-05-13T04:36:27.862519Z","iopub.status.idle":"2024-05-13T04:38:46.129828Z","shell.execute_reply.started":"2024-05-13T04:36:27.862483Z","shell.execute_reply":"2024-05-13T04:38:46.128853Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/211 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ba3db07a6e743c3a863b5802db7b527"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1234 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f029bdd249d4e5680ddef5f47f98029"}},"metadata":{}}]},{"cell_type":"code","source":"def concatenated_feature(feature):\n    mean = torch.mean(feature, dim=1, keepdim=True).expand_as(feature)\n    std_dev = torch.std(feature, dim=1, keepdim=True).expand_as(feature)\n    normalized_feature = (feature - mean) / std_dev\n    list_feature = [feature.view(-1) for feature in normalized_feature]\n    return list_feature","metadata":{"execution":{"iopub.status.busy":"2024-05-13T04:38:46.131095Z","iopub.execute_input":"2024-05-13T04:38:46.131419Z","iopub.status.idle":"2024-05-13T04:38:46.137410Z","shell.execute_reply.started":"2024-05-13T04:38:46.131393Z","shell.execute_reply":"2024-05-13T04:38:46.136417Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"concatenated_query_vectors = concatenated_feature(query_feature)\nconcatenated_gallery_vectors = concatenated_feature(gallery_feature)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T04:38:46.138849Z","iopub.execute_input":"2024-05-13T04:38:46.139197Z","iopub.status.idle":"2024-05-13T04:38:46.275013Z","shell.execute_reply.started":"2024-05-13T04:38:46.139165Z","shell.execute_reply":"2024-05-13T04:38:46.274095Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"def rank1(_class, output):\n    pred_class = output[1]\n    true_class = np.array(_class)\n    if _class == pred_class[0][0]:\n        return True\n    return False","metadata":{"execution":{"iopub.status.busy":"2024-05-13T04:38:46.276480Z","iopub.execute_input":"2024-05-13T04:38:46.276787Z","iopub.status.idle":"2024-05-13T04:38:46.281837Z","shell.execute_reply.started":"2024-05-13T04:38:46.276762Z","shell.execute_reply":"2024-05-13T04:38:46.280735Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def rank5(_class, output):\n    pred_class = output[1]\n    if _class in pred_class[0][:5]:\n        return True\n    return False","metadata":{"execution":{"iopub.status.busy":"2024-05-13T04:38:46.282912Z","iopub.execute_input":"2024-05-13T04:38:46.283158Z","iopub.status.idle":"2024-05-13T04:38:46.291843Z","shell.execute_reply.started":"2024-05-13T04:38:46.283136Z","shell.execute_reply":"2024-05-13T04:38:46.290935Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def rank10(_class, output):\n    pred_class = output[1]\n    if _class in pred_class[0][:10]:\n        return True\n    return False","metadata":{"execution":{"iopub.status.busy":"2024-05-13T04:38:46.292904Z","iopub.execute_input":"2024-05-13T04:38:46.293193Z","iopub.status.idle":"2024-05-13T04:38:46.301367Z","shell.execute_reply.started":"2024-05-13T04:38:46.293168Z","shell.execute_reply":"2024-05-13T04:38:46.300319Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def calc_map(label, output): # mai code lại do chưa hiểu mAP là gì\n    count = 0\n    score = 0\n    good = 0\n    for out in output[1][0]:\n        count += 1\n        if out==label:\n            good += 1\n            score += (good/count)\n    if good==0:\n        return 0\n    return score/good","metadata":{"execution":{"iopub.status.busy":"2024-05-13T04:38:46.302570Z","iopub.execute_input":"2024-05-13T04:38:46.302922Z","iopub.status.idle":"2024-05-13T04:38:46.311090Z","shell.execute_reply.started":"2024-05-13T04:38:46.302897Z","shell.execute_reply":"2024-05-13T04:38:46.310194Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"!pip install faiss-gpu","metadata":{"execution":{"iopub.status.busy":"2024-05-13T04:38:46.312132Z","iopub.execute_input":"2024-05-13T04:38:46.312404Z","iopub.status.idle":"2024-05-13T04:39:02.397121Z","shell.execute_reply.started":"2024-05-13T04:38:46.312379Z","shell.execute_reply":"2024-05-13T04:39:02.396077Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Collecting faiss-gpu\n  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nDownloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hInstalling collected packages: faiss-gpu\nSuccessfully installed faiss-gpu-1.7.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import faiss\n\n\nindex = faiss.IndexIDMap(faiss.IndexFlatIP(2304))\n\nindex.add_with_ids(np.array([t.to('cpu').numpy() for t in concatenated_gallery_vectors]),np.array(gallery_list_labels))\n\n\ndef search(query: str, k=1):\n    encoded_query = query.unsqueeze(dim=0).to('cpu').numpy()\n    top_k = index.search(encoded_query, k)\n    return top_k","metadata":{"execution":{"iopub.status.busy":"2024-05-13T04:39:02.398884Z","iopub.execute_input":"2024-05-13T04:39:02.399273Z","iopub.status.idle":"2024-05-13T04:39:03.230763Z","shell.execute_reply.started":"2024-05-13T04:39:02.399235Z","shell.execute_reply":"2024-05-13T04:39:03.229906Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"rank1_score = 0\nrank5_score = 0\nrank10_score = 0\nap = 0\ncount = 0\nfor query, label in zip(concatenated_query_vectors, query_list_labels):\n    count += 1\n    label = label\n    output = search(query, k=10)\n    rank1_score += rank1(label, output)\n    rank5_score += rank5(label, output)\n    rank10_score += rank10(label, output)\n    print(\"Correct: {}, Total: {}, Incorrect: {}\".format(rank1_score, count, count-rank1_score), end=\"\\r\")\n    ap += calc_map(label, output)\n\nprint(\"Rank1: {}, Rank5: {}, Rank10: {}, mAP: {}\".format(rank1_score/len(query_feature),\n                                                         rank5_score/len(query_feature),\n                                                         rank10_score/len(query_feature), ap/len(query_feature)))","metadata":{"execution":{"iopub.status.busy":"2024-05-13T04:39:03.231899Z","iopub.execute_input":"2024-05-13T04:39:03.232190Z","iopub.status.idle":"2024-05-13T04:42:31.362338Z","shell.execute_reply.started":"2024-05-13T04:39:03.232165Z","shell.execute_reply":"2024-05-13T04:42:31.361312Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Rank1: 0.9848574821852731, Rank5: 0.9979216152019003, Rank10: 0.998812351543943, mAP: 0.9294586456745533\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 5. Visulization","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}